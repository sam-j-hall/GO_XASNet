{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard libraries\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "# --- Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "# --- PyTorch and PyG\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "# --- XASNet\n",
    "from XASNet.data import QM9_XAS\n",
    "from XASNet.data import save_split\n",
    "from XASNet.models import XASNet_GNN, XASNet_GAT, XASNet_GraphNet\n",
    "from XASNet.trainer import GNNTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load in the dataset\n",
    "root = './datasets/mol_dataset.pt'\n",
    "go_spec = QM9_XAS(root=root,\n",
    "                  raw_dir='./datasets/',\n",
    "                  spectra=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QM9_XAS(319)\n",
      "------------\n",
      "Number of graphs: 319\n",
      "Number of features: 17\n",
      "\n",
      "Data(x=[28, 17], edge_index=[2, 72], edge_attr=[72, 6], spectrum=[200], idx=[1], smiles='c12[c:2]3[cH:1][cH:23][c:22]4[c:20]1[c:16]1[c:18]([cH:19][c:21]4[OH:24])[CH:17]4[CH:15]([C:14]5([OH:27])[CH:12]1[C:8]16[c:4]2[c:6]([cH:5][cH:3]3)[CH:7]=[CH:9][C:10]1([CH:11]=[CH:13]5)[O:26]6)[O:25]4')\n",
      "------------\n",
      "Number of nodes: 28\n",
      "Number of edges: 72\n",
      "Average node degree: 2.57\n",
      "Has isolated nodes: False\n",
      "Has self loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "# --- Print details of the dataset\n",
    "print(go_spec)\n",
    "print('------------')\n",
    "print(f'Number of graphs: {len(go_spec)}')\n",
    "print(f'Number of features: {go_spec.num_features}')\n",
    "print('')\n",
    "\n",
    "# --- Print details of the first molecule/graph in dataset\n",
    "data = go_spec[0]\n",
    "\n",
    "print(data)\n",
    "print('------------')\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 244, 'val': 25, 'test': 48}\n"
     ]
    }
   ],
   "source": [
    "# --- Create spilt file with the dataset\n",
    "# --- split into test, validation and test datasets\n",
    "idxs = save_split(\n",
    "    path='./datasets/xasnet-mol-split.npz',\n",
    "    ndata=len(go_spec),\n",
    "    ntrain=244,\n",
    "    nval=25,\n",
    "    ntest=48,\n",
    "    save_split=True,\n",
    "    shuffle=True, \n",
    "    print_nsample=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset length: 244, compiled in 1 loaders\n",
      "Validation dataset length: 25, compiled in 1 loaders\n",
      "Test dataset length: 48, compiled in 1 loaders\n"
     ]
    }
   ],
   "source": [
    "# --- Create variables for each dataset split\n",
    "train_go = [go_spec[i] for i in idxs['train']]\n",
    "val_go = [go_spec[i] for i in idxs['val']]\n",
    "test_go = [go_spec[i] for i in idxs['test']]\n",
    "\n",
    "# --- Save datasets splits into dataloaders\n",
    "train_loader = DataLoader(train_go, batch_size=244, shuffle=True)\n",
    "val_loader = DataLoader(val_go, batch_size=25, shuffle=True)\n",
    "test_loader = DataLoader(test_go, batch_size=48, shuffle=False)\n",
    "\n",
    "print(f'Training dataset length: {len(train_go)}, compiled in {len(train_loader)} loaders')\n",
    "print(f'Validation dataset length: {len(val_go)}, compiled in {len(val_loader)} loaders')\n",
    "print(f'Test dataset length: {len(test_go)}, compiled in {len(test_loader)} loaders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save the dataloader to a file\n",
    "torch.save(test_go, './datasets/test_mol_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define cost functions\n",
    "def RSE_loss(prediction, target):\n",
    "    dE = (300 - 280) / 200\n",
    "    nom = torch.sum(dE*torch.pow((target-prediction), 2))\n",
    "    denom = torch.sum(dE*target)\n",
    "    return torch.sqrt(nom) / denom \n",
    "\n",
    "def RMSE(prediction, target):\n",
    "    return torch.sqrt(torch.mean((target - prediction)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set name for ML model\n",
    "model_name = 'xasnet_model'\n",
    "# --- Set number of epochs to run\n",
    "num_epochs = 500\n",
    "# --- Set the learning rate \n",
    "lr = 0.01\n",
    "# --- Milestones to reduce learning rate in steps \n",
    "milestones = np.arange(10, 100, 10).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is not loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Set device for model to run on\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Create the type of ML model you want to run\n",
    "xasnet_gnn = XASNet_GNN(\n",
    "    gnn_name = 'gcn', # model type\n",
    "    in_channels = [17, 256, 128], # input nodes for each layer\n",
    "    out_channels = [256, 128, 64], # output nodes for each layer\n",
    "    num_targets = 200, # nodes for final output\n",
    "    num_layers = 3, # number of total layers\n",
    "    heads = 1\n",
    ").to(device)\n",
    "\n",
    "# --- Location to save model\n",
    "path_to_model = osp.join('./best_model,', model_name)\n",
    "\n",
    "# --- Check if there is an already existing model\n",
    "if osp.exists(path_to_model):\n",
    "    xasnet_gnn.load_state_dict(torch.load(path_to_model))\n",
    "else:\n",
    "    print('Model is not loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XASNet_GNN(\n",
      "  (batch_norms): ModuleList()\n",
      "  (interaction_layers): ModuleList(\n",
      "    (0): GCNConv(17, 256)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): GCNConv(256, 128)\n",
      "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): GCNConv(128, 64)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.6, inplace=False)\n",
      "  (out): Linear(in_features=64, out_features=200, bias=True)\n",
      ")\n",
      "----\n",
      " Model will be trained on: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- View the details of the created model\n",
    "print(xasnet_gnn)\n",
    "print('----')\n",
    "print(f' Model will be trained on: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model = xasnet_gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set additional ML parameters\n",
    "optimizer = torch.optim.AdamW(chosen_model.parameters(), lr=lr)\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "loss_fn2 = torch.nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                                                 milestones=milestones,\n",
    "                                                 gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create trainier\n",
    "trainer = GNNTrainer(model = chosen_model,\n",
    "                     model_name = model_name,\n",
    "                     device = device,\n",
    "                     metric_path = './metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]c:\\Users\\a3782\\AppData\\Local\\anaconda3\\envs\\xasnet-xai\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:432: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "  1%|          | 3/500 [00:00<00:40, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | average train loss = 0.00009  and average validation loss = 0.00207  |learning rate = 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 29/500 [00:01<00:29, 16.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 | average train loss = 0.00002  and average validation loss = 0.00049  |learning rate = 0.00640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 53/500 [00:03<00:26, 16.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 | average train loss = 0.00002  and average validation loss = 0.00043  |learning rate = 0.00328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 77/500 [00:04<00:28, 14.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75 | average train loss = 0.00002  and average validation loss = 0.00045  |learning rate = 0.00210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 103/500 [00:06<00:25, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100 | average train loss = 0.00002  and average validation loss = 0.00043  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 129/500 [00:08<00:24, 15.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125 | average train loss = 0.00001  and average validation loss = 0.00043  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 153/500 [00:09<00:22, 15.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 150 | average train loss = 0.00001  and average validation loss = 0.00042  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 179/500 [00:11<00:20, 15.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 175 | average train loss = 0.00001  and average validation loss = 0.00043  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 203/500 [00:13<00:18, 15.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200 | average train loss = 0.00001  and average validation loss = 0.00041  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 229/500 [00:14<00:17, 15.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 225 | average train loss = 0.00001  and average validation loss = 0.00042  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 253/500 [00:16<00:16, 14.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 250 | average train loss = 0.00001  and average validation loss = 0.00040  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 277/500 [00:17<00:13, 15.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 275 | average train loss = 0.00001  and average validation loss = 0.00041  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 303/500 [00:19<00:12, 15.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 300 | average train loss = 0.00001  and average validation loss = 0.00039  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 329/500 [00:21<00:10, 15.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 325 | average train loss = 0.00001  and average validation loss = 0.00040  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 353/500 [00:22<00:09, 15.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 350 | average train loss = 0.00001  and average validation loss = 0.00039  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 379/500 [00:24<00:07, 15.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 375 | average train loss = 0.00001  and average validation loss = 0.00039  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 403/500 [00:25<00:06, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 400 | average train loss = 0.00001  and average validation loss = 0.00039  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 427/500 [00:27<00:04, 15.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 425 | average train loss = 0.00001  and average validation loss = 0.00039  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 453/500 [00:28<00:02, 16.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 450 | average train loss = 0.00001  and average validation loss = 0.00038  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 479/500 [00:30<00:01, 15.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 475 | average train loss = 0.00001  and average validation loss = 0.00039  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:32<00:00, 15.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- Train the ML model\n",
    "trainer.train_val(train_loader, val_loader, optimizer, RSE_loss,\n",
    "                  scheduler, num_epochs, write_every=25, train_graphnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xasnet-xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
