{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard libraries\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "# --- Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "# --- PyTorch and PyG\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "# --- XASNet\n",
    "from XASNet.data import QM9_XAS\n",
    "from XASNet.data import save_split\n",
    "from XASNet.models import XASNet_GNN, XASNet_GAT, XASNet_GraphNet\n",
    "from XASNet.trainer import GNNTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load in the dataset\n",
    "root = './datasets/mol_dataset.pt'\n",
    "go_spec = QM9_XAS(root=root,\n",
    "                  raw_dir='./datasets/',\n",
    "                  spectra=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QM9_XAS(317)\n",
      "------------\n",
      "Number of graphs: 317\n",
      "Number of features: 15\n",
      "\n",
      "Data(x=[32, 15], edge_index=[2, 76], edge_attr=[76, 6], spectrum=[200], pos=[32, 3], z=[32], idx=[1], smiles='c12[c:2]3[cH:1][cH:25][c:24]4[c:22]1[c:17]1[c:19]([cH:20][cH:23]4)[C:18]([C:21](=[O:26])[OH:27])=[CH:16][C:15]4=[CH:14][CH:12]=[C:11]5[C:9]([OH:30])([CH:4]2[C:6]([OH:31])([C:5]([C:8](=[O:28])[OH:29])=[CH:3]3)[CH:7]=[CH:10]5)[CH:13]41')\n",
      "------------\n",
      "Number of nodes: 32\n",
      "Number of edges: 76\n",
      "Average node degree: 2.38\n",
      "Has isolated nodes: False\n",
      "Has self loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "# --- Print details of the dataset\n",
    "print(go_spec)\n",
    "print('------------')\n",
    "print(f'Number of graphs: {len(go_spec)}')\n",
    "print(f'Number of features: {go_spec.num_features}')\n",
    "print('')\n",
    "\n",
    "# --- Print details of the first molecule/graph in dataset\n",
    "data = go_spec[0]\n",
    "\n",
    "print(data)\n",
    "print('------------')\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 238, 'val': 29, 'test': 48}\n"
     ]
    }
   ],
   "source": [
    "# --- Create spilt file with the dataset\n",
    "# --- split into test, validation and test datasets\n",
    "idxs = save_split(\n",
    "    path='./datasets/xasnet-mol-split.npz',\n",
    "    ndata=len(go_spec),\n",
    "    ntrain=238,\n",
    "    nval=29,\n",
    "    ntest=48,\n",
    "    save_split=True,\n",
    "    shuffle=True, \n",
    "    print_nsample=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset length: 238, compiled in 1 loaders\n",
      "Validation dataset length: 29, compiled in 1 loaders\n",
      "Test dataset length: 48, compiled in 1 loaders\n"
     ]
    }
   ],
   "source": [
    "# --- Create variables for each dataset split\n",
    "train_go = [go_spec[i] for i in idxs['train']]\n",
    "val_go = [go_spec[i] for i in idxs['val']]\n",
    "test_go = [go_spec[i] for i in idxs['test']]\n",
    "\n",
    "# --- Save datasets splits into dataloaders\n",
    "train_loader = DataLoader(train_go, batch_size=238, shuffle=True)\n",
    "val_loader = DataLoader(val_go, batch_size=29, shuffle=True)\n",
    "test_loader = DataLoader(test_go, batch_size=48, shuffle=False)\n",
    "\n",
    "print(f'Training dataset length: {len(train_go)}, compiled in {len(train_loader)} loaders')\n",
    "print(f'Validation dataset length: {len(val_go)}, compiled in {len(val_loader)} loaders')\n",
    "print(f'Test dataset length: {len(test_go)}, compiled in {len(test_loader)} loaders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save the dataloader to a file\n",
    "torch.save(test_go, './datasets/mol_test_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define cost functions\n",
    "def RSE_loss(prediction, target):\n",
    "    dE = (300 - 280) / 200\n",
    "    nom = torch.sum(dE*torch.pow((target-prediction), 2))\n",
    "    denom = torch.sum(dE*target)\n",
    "    return torch.sqrt(nom) / denom \n",
    "\n",
    "def RMSE_loss(prediction, target):\n",
    "    return torch.sqrt(torch.mean((target - prediction)**2))\n",
    "\n",
    "def MSE_loss(prediction, target):\n",
    "    return torch.mean((target - prediction)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500, 700]\n"
     ]
    }
   ],
   "source": [
    "# --- Set number of epochs to run\n",
    "num_epochs = 300\n",
    "# --- Set the learning rate \n",
    "lr = 0.01\n",
    "# --- Milestones to reduce learning rate in steps \n",
    "milestones = np.arange(500, 900, 200).tolist()\n",
    "print(milestones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XASNet GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is not loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Set name for ML model\n",
    "model_name = 'xasnet_gnn_model'\n",
    "\n",
    "# --- Set device for model to run on\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Create the type of ML model you want to run\n",
    "xasnet_gnn = XASNet_GNN(\n",
    "    gnn_name = 'gcn', # model type\n",
    "    in_channels = [15, 64, 128], # input nodes for each layer\n",
    "    out_channels = [64, 128, 256], # output nodes for each layer\n",
    "    num_targets = 200, # nodes for final output\n",
    "    num_layers = 3, # number of total layers\n",
    "    heads = 1\n",
    ").to(device)\n",
    "\n",
    "# --- Location to save model\n",
    "path_to_model = osp.join('./best_model,', model_name)\n",
    "\n",
    "# --- Check if there is an already existing model\n",
    "if osp.exists(path_to_model):\n",
    "    xasnet_gnn.load_state_dict(torch.load(path_to_model))\n",
    "else:\n",
    "    print('Model is not loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XASNet_GNN(\n",
      "  (batch_norms): ModuleList(\n",
      "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (interaction_layers): ModuleList(\n",
      "    (0): GCNConv(15, 64)\n",
      "    (1): GCNConv(64, 128)\n",
      "    (2): GCNConv(128, 256)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.6, inplace=False)\n",
      "  (out): Linear(in_features=256, out_features=200, bias=True)\n",
      ")\n",
      "----\n",
      " Model will be trained on: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- View the details of the created model\n",
    "print(xasnet_gnn)\n",
    "print('----')\n",
    "print(f' Model will be trained on: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XASNet GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is not loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Set name for ML model\n",
    "model_name = 'xasnet_gat_model'\n",
    "\n",
    "# --- Set device for model to run on\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Create the type of ML model you want to run\n",
    "xasnet_gat = XASNet_GAT(\n",
    "    node_features_dim=15,\n",
    "    in_channels=[128, 128, 128, 128],\n",
    "    out_channels=[128, 128, 128, 400],\n",
    "    targets=200,\n",
    "    n_layers=4,\n",
    "    n_heads=3,\n",
    "    gat_type='gatv2_custom',\n",
    "    use_residuals=True,\n",
    "    use_jk=True\n",
    ").to(device)\n",
    "\n",
    "# --- Location to save model\n",
    "path_to_model = osp.join('./best_model,', model_name)\n",
    "\n",
    "# --- Check if there is an already existing model\n",
    "if osp.exists(path_to_model):\n",
    "    xasnet_gat.load_state_dict(torch.load(path_to_model))\n",
    "else:\n",
    "    print('Model is not loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XASNet_GAT(\n",
      "  (pre_layer): LinearLayer(\n",
      "    (linear): Linear(in_features=15, out_features=128, bias=False)\n",
      "    (_activation): ReLU(inplace=True)\n",
      "  )\n",
      "  (res_block): Residual_block(\n",
      "    (res_layers): Sequential(\n",
      "      (0): LinearLayer(\n",
      "        (linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (_activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): LinearLayer(\n",
      "        (linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (_activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): LinearLayer(\n",
      "        (linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (_activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): LinearLayer(\n",
      "        (linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (_activation): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (gat_layers): ModuleList(\n",
      "    (0): GATv2LayerCus(128, 128)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): GATv2LayerCus(384, 128)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): GATv2LayerCus(384, 128)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): GATv2LayerCus(384, 400)\n",
      "  )\n",
      "  (lstm): LSTM(384, 128, num_layers=3, batch_first=True, bidirectional=True)\n",
      "  (attn): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (linear_out): LinearLayer(\n",
      "    (linear): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (_activation): Identity()\n",
      "  )\n",
      ")\n",
      "----\n",
      " Model will be trained on: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- View the details of the created model\n",
    "print(xasnet_gat)\n",
    "print('----')\n",
    "print(f' Model will be trained on: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XASNet GraphNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is not loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Set name for ML model\n",
    "model_name = 'xasnet_graphnet_model'\n",
    "\n",
    "# --- Set device for model to run on\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Create the type of ML model you want to run\n",
    "xasnet_graphnet = XASNet_GraphNet(\n",
    "    node_dim=17,\n",
    "    edge_dim=6,\n",
    "    hidden_channels=512,\n",
    "    out_channels=200,\n",
    "    gat_hidd=512,\n",
    "    gat_out=200,\n",
    "    n_layers=3,\n",
    "    n_targets=200\n",
    ").to(device)\n",
    "\n",
    "# --- Location to save model\n",
    "path_to_model = osp.join('./best_model,', model_name)\n",
    "\n",
    "# --- Check if there is an already existing model\n",
    "if osp.exists(path_to_model):\n",
    "    xasnet_graphnet.load_state_dict(torch.load(path_to_model))\n",
    "else:\n",
    "    print('Model is not loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XASNet_GraphNet(\n",
      "  (graphnets): ModuleList(\n",
      "    (0): GraphNetwork(\n",
      "      (gatencoder): GATEncoder(\n",
      "        (gats): ModuleList(\n",
      "          (0): GATv2Conv(17, 512, heads=3)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): GATv2Conv(1536, 512, heads=3)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): GATv2Conv(1536, 512, heads=3)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): GATv2Conv(1536, 200, heads=1)\n",
      "        )\n",
      "      )\n",
      "      (node_model): NodeModel(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=229, out_features=512, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_model): EdgeModel(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=606, out_features=512, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (global_model): GlobalModel(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=600, out_features=512, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1-2): 2 x GraphNetwork(\n",
      "      (gatencoder): GATEncoder(\n",
      "        (gats): ModuleList(\n",
      "          (0): GATv2Conv(17, 512, heads=3)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): GATv2Conv(1536, 512, heads=3)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): GATv2Conv(1536, 512, heads=3)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): GATv2Conv(1536, 200, heads=1)\n",
      "        )\n",
      "      )\n",
      "      (node_model): NodeModel(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=800, out_features=512, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_model): EdgeModel(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=800, out_features=512, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (global_model): GlobalModel(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=600, out_features=512, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (output_dense): Linear(in_features=200, out_features=200, bias=True)\n",
      ")\n",
      "----\n",
      " Model will be trained on: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- View the details of the created model\n",
    "print(xasnet_graphnet)\n",
    "print('----')\n",
    "print(f' Model will be trained on: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model = xasnet_gat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set additional ML parameters\n",
    "optimizer = torch.optim.AdamW(chosen_model.parameters(), lr=lr, weight_decay=1e-5, betas=(0.9, 0.99), eps=1e-08, amsgrad=True)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.8)\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=100, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create trainier\n",
    "trainer = GNNTrainer(model = chosen_model,\n",
    "                     model_name = model_name,\n",
    "                     device = device,\n",
    "                     metric_path = './metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]c:\\Users\\a3782\\AppData\\Local\\anaconda3\\envs\\xasnet-xai\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:432: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "  0%|          | 1/300 [00:01<08:50,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | average train loss = 0.00131  and average validation loss = 1.26981  |learning rate = 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 26/300 [00:43<07:34,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 | average train loss = 0.00027  and average validation loss = 0.00123  |learning rate = 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 51/300 [01:47<06:29,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 | average train loss = 0.00010  and average validation loss = 0.00048  |learning rate = 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 76/300 [02:49<06:13,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75 | average train loss = 0.00008  and average validation loss = 0.00047  |learning rate = 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 101/300 [04:11<15:20,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100 | average train loss = 0.00008  and average validation loss = 0.00046  |learning rate = 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 126/300 [05:11<08:26,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125 | average train loss = 0.00008  and average validation loss = 0.00045  |learning rate = 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 151/300 [06:13<04:57,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 150 | average train loss = 0.00008  and average validation loss = 0.00045  |learning rate = 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 176/300 [07:15<04:07,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 175 | average train loss = 0.00008  and average validation loss = 0.00044  |learning rate = 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 201/300 [08:16<02:54,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200 | average train loss = 0.00007  and average validation loss = 0.00045  |learning rate = 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 226/300 [09:17<02:04,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 225 | average train loss = 0.00007  and average validation loss = 0.00044  |learning rate = 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 251/300 [10:18<01:22,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 250 | average train loss = 0.00007  and average validation loss = 0.00045  |learning rate = 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 276/300 [11:20<00:39,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 275 | average train loss = 0.00007  and average validation loss = 0.00045  |learning rate = 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [12:21<00:00,  2.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# --- Train the ML model\n",
    "trainer.train_val(train_loader, val_loader, optimizer, MSE_loss,\n",
    "                  scheduler, num_epochs, write_every=25, train_graphnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xasnet-xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
