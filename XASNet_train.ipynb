{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard libraries\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "# --- Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "# --- PyTorch and PyG\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "# --- XASNet\n",
    "from XASNet.data import QM9_XAS\n",
    "from XASNet.data import save_split\n",
    "from XASNet.models import XASNet_GNN, XASNet_GAT, XASNet_GraphNet\n",
    "from XASNet.trainer import GNNTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load in the dataset\n",
    "root = './datasets/mol_dataset.pt'\n",
    "go_spec = QM9_XAS(root=root,\n",
    "                  raw_dir='./datasets/',\n",
    "                  spectra=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QM9_XAS(319)\n",
      "------------\n",
      "Number of graphs: 319\n",
      "Number of features: 17\n",
      "\n",
      "Data(x=[28, 17], edge_index=[2, 72], edge_attr=[72, 6], spectrum=[200], idx=[1], smiles='c12[c:2]3[cH:1][cH:23][c:22]4[c:20]1[c:16]1[c:18]([cH:19][c:21]4[OH:24])[CH:17]4[CH:15]([C:14]5([OH:27])[CH:12]1[C:8]16[c:4]2[c:6]([cH:5][cH:3]3)[CH:7]=[CH:9][C:10]1([CH:11]=[CH:13]5)[O:26]6)[O:25]4')\n",
      "------------\n",
      "Number of nodes: 28\n",
      "Number of edges: 72\n",
      "Average node degree: 2.57\n",
      "Has isolated nodes: False\n",
      "Has self loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "# --- Print details of the dataset\n",
    "print(go_spec)\n",
    "print('------------')\n",
    "print(f'Number of graphs: {len(go_spec)}')\n",
    "print(f'Number of features: {go_spec.num_features}')\n",
    "print('')\n",
    "\n",
    "# --- Print details of the first molecule/graph in dataset\n",
    "data = go_spec[0]\n",
    "\n",
    "print(data)\n",
    "print('------------')\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create spilt file with the dataset\n",
    "# --- split into test, validation and test datasets\n",
    "idxs = save_split(\n",
    "    path='./datasets/xasnet-mol-split.npz',\n",
    "    ndata=len(go_spec),\n",
    "    ntrain=244,\n",
    "    nval=25,\n",
    "    ntest=48,\n",
    "    save_split=True,\n",
    "    shuffle=True, \n",
    "    print_nsample=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset length: 244, compiled in 1 loaders\n",
      "Validation dataset length: 25, compiled in 1 loaders\n",
      "Test dataset length: 48, compiled in 1 loaders\n"
     ]
    }
   ],
   "source": [
    "# --- Create variables for each dataset split\n",
    "train_go = [go_spec[i] for i in idxs['train']]\n",
    "val_go = [go_spec[i] for i in idxs['val']]\n",
    "test_go = [go_spec[i] for i in idxs['test']]\n",
    "\n",
    "# --- Save datasets splits into dataloaders\n",
    "train_loader = DataLoader(train_go, batch_size=244, shuffle=True)\n",
    "val_loader = DataLoader(val_go, batch_size=25, shuffle=True)\n",
    "test_loader = DataLoader(test_go, batch_size=48, shuffle=False)\n",
    "\n",
    "print(f'Training dataset length: {len(train_go)}, compiled in {len(train_loader)} loaders')\n",
    "print(f'Validation dataset length: {len(val_go)}, compiled in {len(val_loader)} loaders')\n",
    "print(f'Test dataset length: {len(test_go)}, compiled in {len(test_loader)} loaders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save the dataloader to a file\n",
    "torch.save(test_go, './datasets/test_mol_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define cost functions\n",
    "def RSE_loss(prediction, target):\n",
    "    dE = (300 - 280) / 200\n",
    "    nom = torch.sum(dE*torch.pow((target-prediction), 2))\n",
    "    denom = torch.sum(dE*target)\n",
    "    return torch.sqrt(nom) / denom \n",
    "\n",
    "def RMSE(prediction, target):\n",
    "    return torch.sqrt(torch.mean((target - prediction)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set name for ML model\n",
    "model_name = 'xasnet_model'\n",
    "# --- Set number of epochs to run\n",
    "num_epochs = 500\n",
    "# --- Set the learning rate \n",
    "lr = 0.01\n",
    "# --- Milestones to reduce learning rate in steps \n",
    "milestones = np.arange(10, 100, 10).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XASNet GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is not loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Set device for model to run on\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Create the type of ML model you want to run\n",
    "xasnet_gnn = XASNet_GNN(\n",
    "    gnn_name = 'gcn', # model type\n",
    "    in_channels = [17, 256, 128], # input nodes for each layer\n",
    "    out_channels = [256, 128, 64], # output nodes for each layer\n",
    "    num_targets = 200, # nodes for final output\n",
    "    num_layers = 3, # number of total layers\n",
    "    heads = 1\n",
    ").to(device)\n",
    "\n",
    "# --- Location to save model\n",
    "path_to_model = osp.join('./best_model,', model_name)\n",
    "\n",
    "# --- Check if there is an already existing model\n",
    "if osp.exists(path_to_model):\n",
    "    xasnet_gnn.load_state_dict(torch.load(path_to_model))\n",
    "else:\n",
    "    print('Model is not loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XASNet_GNN(\n",
      "  (batch_norms): ModuleList()\n",
      "  (interaction_layers): ModuleList(\n",
      "    (0): GCNConv(17, 256)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): GCNConv(256, 128)\n",
      "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): GCNConv(128, 64)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.6, inplace=False)\n",
      "  (out): Linear(in_features=64, out_features=200, bias=True)\n",
      ")\n",
      "----\n",
      " Model will be trained on: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- View the details of the created model\n",
    "print(xasnet_gnn)\n",
    "print('----')\n",
    "print(f' Model will be trained on: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XASNet GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is not loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Set device for model to run on\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Create the type of ML model you want to run\n",
    "xasnet_gat = XASNet_GAT(\n",
    "    node_features_dim=17,\n",
    "    in_channels=[128, 128, 128, 128],\n",
    "    out_channels=[128, 128, 128, 400],\n",
    "    targets=200,\n",
    "    n_layers=4,\n",
    "    n_heads=3,\n",
    "    gat_type='gatv2_custom',\n",
    "    use_residuals=True,\n",
    "    use_jk=True\n",
    ").to(device)\n",
    "\n",
    "# --- Location to save model\n",
    "path_to_model = osp.join('./best_model,', model_name)\n",
    "\n",
    "# --- Check if there is an already existing model\n",
    "if osp.exists(path_to_model):\n",
    "    xasnet_gat.load_state_dict(torch.load(path_to_model))\n",
    "else:\n",
    "    print('Model is not loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XASNet_GAT(\n",
      "  (pre_layer): LinearLayer(\n",
      "    (linear): Linear(in_features=17, out_features=128, bias=False)\n",
      "    (_activation): ReLU(inplace=True)\n",
      "  )\n",
      "  (res_block): Residual_block(\n",
      "    (res_layers): Sequential(\n",
      "      (0): LinearLayer(\n",
      "        (linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (_activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): LinearLayer(\n",
      "        (linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (_activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): LinearLayer(\n",
      "        (linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (_activation): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): LinearLayer(\n",
      "        (linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "        (_activation): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (gat_layers): ModuleList(\n",
      "    (0): GATv2LayerCus(128, 128)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): GATv2LayerCus(384, 128)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): GATv2LayerCus(384, 128)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): GATv2LayerCus(384, 400)\n",
      "  )\n",
      "  (lstm): LSTM(384, 128, num_layers=3, batch_first=True, bidirectional=True)\n",
      "  (attn): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (linear_out): LinearLayer(\n",
      "    (linear): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (_activation): Identity()\n",
      "  )\n",
      ")\n",
      "----\n",
      " Model will be trained on: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- View the details of the created model\n",
    "print(xasnet_gat)\n",
    "print('----')\n",
    "print(f' Model will be trained on: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XASNet GraphNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is not loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Set device for model to run on\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Create the type of ML model you want to run\n",
    "xasnet_graphnet = XASNet_GraphNet(\n",
    "    node_dim=17,\n",
    "    edge_dim=6,\n",
    "    hidden_channels=512,\n",
    "    out_channels=200,\n",
    "    gat_hidd=512,\n",
    "    gat_out=200,\n",
    "    n_layers=3,\n",
    "    n_targets=200\n",
    ").to(device)\n",
    "\n",
    "# --- Location to save model\n",
    "path_to_model = osp.join('./best_model,', model_name)\n",
    "\n",
    "# --- Check if there is an already existing model\n",
    "if osp.exists(path_to_model):\n",
    "    xasnet_graphnet.load_state_dict(torch.load(path_to_model))\n",
    "else:\n",
    "    print('Model is not loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XASNet_GraphNet(\n",
      "  (graphnets): ModuleList(\n",
      "    (0): GraphNetwork(\n",
      "      (gatencoder): GATEncoder(\n",
      "        (gats): ModuleList(\n",
      "          (0): GATv2Conv(17, 512, heads=3)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): GATv2Conv(1536, 512, heads=3)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): GATv2Conv(1536, 512, heads=3)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): GATv2Conv(1536, 200, heads=1)\n",
      "        )\n",
      "      )\n",
      "      (node_model): NodeModel(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=229, out_features=512, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_model): EdgeModel(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=606, out_features=512, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (global_model): GlobalModel(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=600, out_features=512, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1-2): 2 x GraphNetwork(\n",
      "      (gatencoder): GATEncoder(\n",
      "        (gats): ModuleList(\n",
      "          (0): GATv2Conv(17, 512, heads=3)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): GATv2Conv(1536, 512, heads=3)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): GATv2Conv(1536, 512, heads=3)\n",
      "          (5): ReLU(inplace=True)\n",
      "          (6): GATv2Conv(1536, 200, heads=1)\n",
      "        )\n",
      "      )\n",
      "      (node_model): NodeModel(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=800, out_features=512, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (edge_model): EdgeModel(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=800, out_features=512, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (global_model): GlobalModel(\n",
      "        (mlp): Sequential(\n",
      "          (0): Linear(in_features=600, out_features=512, bias=True)\n",
      "          (1): ReLU(inplace=True)\n",
      "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
      "          (3): ReLU(inplace=True)\n",
      "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (output_dense): Linear(in_features=200, out_features=200, bias=True)\n",
      ")\n",
      "----\n",
      " Model will be trained on: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- View the details of the created model\n",
    "print(xasnet_graphnet)\n",
    "print('----')\n",
    "print(f' Model will be trained on: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model = xasnet_graphnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set additional ML parameters\n",
    "optimizer = torch.optim.AdamW(chosen_model.parameters(), lr=lr, weight_decay=1e-5) #betas=(0.9, 0.99), eps=1e-08, amsgrad=True)\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "loss_fn2 = torch.nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                                                 milestones=milestones,\n",
    "                                                 gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create trainier\n",
    "trainer = GNNTrainer(model = chosen_model,\n",
    "                     model_name = model_name,\n",
    "                     device = device,\n",
    "                     metric_path = './metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/home/samjhall/anaconda3/envs/xasnet-xai/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:432: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "  0%|          | 1/500 [00:01<09:01,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | average train loss = 0.00432  and average validation loss = 0.11220  |learning rate = 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 26/500 [00:14<04:02,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 | average train loss = 0.00107  and average validation loss = 0.00888  |learning rate = 0.00640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 51/500 [00:27<03:55,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 | average train loss = 0.00022  and average validation loss = 0.00146  |learning rate = 0.00328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 76/500 [00:39<03:12,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75 | average train loss = 0.00008  and average validation loss = 0.00062  |learning rate = 0.00210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/500 [00:50<03:07,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100 | average train loss = 0.00005  and average validation loss = 0.00051  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 126/500 [01:01<02:39,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125 | average train loss = 0.00004  and average validation loss = 0.00050  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 151/500 [01:13<02:38,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 150 | average train loss = 0.00003  and average validation loss = 0.00051  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 176/500 [01:24<02:12,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 175 | average train loss = 0.00003  and average validation loss = 0.00048  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/500 [01:34<02:03,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200 | average train loss = 0.00002  and average validation loss = 0.00056  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 226/500 [01:44<01:53,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 225 | average train loss = 0.00002  and average validation loss = 0.00057  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 251/500 [01:54<01:39,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 250 | average train loss = 0.00002  and average validation loss = 0.00051  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 276/500 [02:05<01:39,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 275 | average train loss = 0.00002  and average validation loss = 0.00045  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/500 [02:15<01:20,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 300 | average train loss = 0.00002  and average validation loss = 0.00049  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 326/500 [02:25<01:09,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 325 | average train loss = 0.00002  and average validation loss = 0.00051  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 351/500 [02:35<01:01,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 350 | average train loss = 0.00002  and average validation loss = 0.00049  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 376/500 [02:46<00:52,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 375 | average train loss = 0.00002  and average validation loss = 0.00046  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/500 [02:58<00:50,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 400 | average train loss = 0.00002  and average validation loss = 0.00049  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 426/500 [03:10<00:36,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 425 | average train loss = 0.00002  and average validation loss = 0.00047  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 451/500 [03:22<00:23,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 450 | average train loss = 0.00002  and average validation loss = 0.00051  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 476/500 [03:34<00:10,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 475 | average train loss = 0.00002  and average validation loss = 0.00049  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:45<00:00,  2.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- Train the ML model\n",
    "trainer.train_val(train_loader, val_loader, optimizer, RSE_loss,\n",
    "                  scheduler, num_epochs, write_every=25, train_graphnet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xasnet-xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
